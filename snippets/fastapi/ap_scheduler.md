# APScheduler ë¥¼ ì´ìš©í•˜ì—¬ API ì„œë²„ì—ì„œ ë°°ì¹˜ëŒë¦¬ê¸°

## main.py

```py
@asynccontextmanager
async def lifespan(app: FastAPI):
    if APSCHEDULER_BATCH_IS_ACTIVE:
        scheduler.start()  # â± APScheduler ì‹œì‘
        load_app_schedules()  # {APP}/schedules/*.py ìˆœíšŒ
        yield  # FastAPI ì•± ì‹¤í–‰
        scheduler.shutdown(wait=True)  # â›” APScheduler ì¢…ë£Œ (í•˜ë˜ ì‘ì—… ë§ˆë¬´ë¦¬ í›„)
    else:
        logger.info(
            "Local, Stage í™˜ê²½ì´ê±°ë‚˜ ECS ë‚´ë¶€ê°€ ì•„ë‹Œ ê²½ìš°, Batch ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
        yield


app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    lifespan=lifespan,
    description=read_md_file("docs/index.md"),
    debug=settings.APP_DEBUG is True,
    docs_url=(
        None
        if settings.APP_ENV.lower() == ServiceEnvironment.PROD.value
        else "/swagger"
    ),
    openapi_tags=APIRouterTagsEnum.generate_openapi_tags(),
    responses={
        200: {"description": "ì„±ê³µ ì‘ë‹µ"},
        401: {
            "description": "ì¸ì¦ ì˜¤ë¥˜",
            "model": MessageOut,
            "content": {
                "application/json": {"example": {"message": "ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."}}
            },
        },
        400: {
            "description": "í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜",
            "model": MessageOut,
            "content": {
                "application/json": {
                    "example": {"message": "ìš”ì²­ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."}
                }
            },
        },
        403: {
            "description": "ì¸ì¦ ì˜¤ë¥˜",
            "model": MessageOut,
            "content": {
                "application/json": {"example": {"message": "ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."}}
            },
        },
        500: {
            "description": "ì„œë²„ ì˜¤ë¥˜",
            "model": MessageOut,
            "content": {
                "application/json": {
                    "example": {"message": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}
                }
            },
        },
    },
)
```

## batch_util.py

```py
import logging
import time
import traceback
from functools import wraps
from typing import Callable

from apscheduler.triggers.base import BaseTrigger

from app.Core.consts.base import (
    APSCHEDULER_BATCH_TASK_TIME_LIMIT_SEC,
)
from app.Core.consts.exc_handler import SLACK_MESSAGE_LIMIT_STACK_TRACE
from app.Core.utils.slack import SlackMessageUtil
from app.cache import Cache

logger = logging.getLogger(__name__)


def with_distributed_lock(lock_key: str, ttl_sec: int):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            lock_acquired = await Cache.set_lock(lock_key, value="1", expire=ttl_sec)
            if lock_acquired:
                logger.info(
                    f"[batch_schedule] lock_key={lock_key} (TTL={ttl_sec}ì´ˆ) íšë“"
                )
                start = time.monotonic()  # âœ… ì‹œì‘ì‹œê°„ ê¸°ë¡
                try:
                    result = await func(*args, **kwargs)
                    return result

                except Exception as e:
                    error_stack_trace = traceback.format_exc()
                    logger.error(
                        f"[batch_schedule] ì˜¤ë¥˜ ë°œìƒ: {e}\n{error_stack_trace}"
                    )

                    text_limit = SLACK_MESSAGE_LIMIT_STACK_TRACE
                    if len(error_stack_trace) > text_limit:
                        error_stack_trace = (
                            "ì „ë¬¸ìƒëµ...\n" + error_stack_trace[-text_limit:]
                        )
                    await SlackMessageUtil.send_formatted_auto(
                        main_message=f"[batch_schedule] ì˜¤ë¥˜ ë°œìƒ: {e}",
                        info_message=f"- lock_key: {lock_key}\n\n- Error Stack: {error_stack_trace}",
                    )

                finally:
                    end = time.monotonic()  # âœ… ì¢…ë£Œì‹œê°„ ê¸°ë¡
                    duration = end - start
                    time_limit = APSCHEDULER_BATCH_TASK_TIME_LIMIT_SEC
                    if duration >= APSCHEDULER_BATCH_TASK_TIME_LIMIT_SEC:
                        logger.warning(
                            f"[batch_schedule] {lock_key} ì‘ì—…ì´ {duration:.2f}ì´ˆ ì†Œìš”ë¨ (ì§€ì—° ê²½ê³ )"
                        )
                        await SlackMessageUtil.send_formatted_auto(
                            main_message=f"âš ï¸ [batch_schedule] ì‘ì—… ì§€ì—° ê²½ê³ ",
                            info_message=f"- ì‘ì—…: {lock_key}\n- ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ ({time_limit}ì´ˆ ì´ˆê³¼)",
                        )
            else:
                logger.debug(
                    f"[batch_schedule] lock_key={lock_key} (TTL={ttl_sec}ì´ˆ) íšë“ ì‹¤íŒ¨"
                )

        return wrapper

    return decorator


def batch_schedule(
    trigger: BaseTrigger | str,
    *,
    job_id: str = None,
    job_name: str = None,
    ttl_sec: int = 5,  # ì‘ì—…ì˜ ì¤‘ë³µ íŠ¸ë¦¬ê±° ë°©ì§€ìš©
    replace_existing: bool = True,
):
    """
    ìŠ¤ì¼€ì¤„ë§ëœ ì‘ì—…ì„ ìƒì„±í• ë•Œ í™œìš©ë˜ëŠ” decorator

    - APScheduler ì‘ì—… + ë¶„ì‚° ë½ ë˜í•‘
    - ë¶„ì‚° lock(by Redis): ë¶„ì‚°í™˜ê²½ì—ì„œ ì¤‘ë³µì—†ì´ ì‹¤í–‰í•˜ê¸°ìœ„í•¨
    - ë¶„ì‚° lock ì„ ì ìš©í•œ ì´ìœ : FastAPI ì–´í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ê°ê° ë„ìš°ê¸° ë•Œë¬¸ì—
        ì‹¤í–‰ë˜ëŠ” ECS task ê°œìˆ˜ë§Œí¼ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ìƒì„±ë˜ê³  ì¤‘ë³µ task íŠ¸ë¦¬ê±°ê°€ ë°œìƒí•¨.
        ì´ë•Œ 1íšŒë§Œ ì‹¤ì œ ë¡œì§ì´ ì‹¤í–‰ë˜ë„ë¡ ì²˜ë¦¬í•˜ê¸° ìœ„í•¨.

    [ì˜ˆì œ]
    @batch_schedule("interval", minutes=60)
    async def send_hourly_report():
        logger.info("ğŸ“¨ [ë§¤ì‹œê°„] ë³´ê³ ì„œ ì „ì†¡ ì‘ì—… ì‹¤í–‰ ì¤‘")
    """

    def decorator(func: Callable):
        from app.scheduler import scheduler

        # id ìë™ ìƒì„±: "batch.{ëª¨ë“ˆ ê²½ë¡œ}.{í•¨ìˆ˜ëª…}"
        _job_id = job_id or f"batch.{func.__module__}.{func.__name__}"
        _job_name = job_name or job_id
        lock_key = f"batch:{_job_id}"

        @with_distributed_lock(lock_key, ttl_sec=ttl_sec)
        @wraps(func)
        async def wrapped(*args, **kwargs):
            return await func(*args, **kwargs)

        # ì‹¤ì œ ë“±ë¡
        scheduler.add_job(
            wrapped,
            trigger=trigger,
            id=_job_id,
            name=_job_name,
            replace_existing=replace_existing,
        )

        return wrapped

    return decorator
```

## scheduler.py

```py
"""
# app/scheduler.py

APScheduler ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ batch ì‘ì—…ì„ ì„¸íŒ…í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
"""

import glob
import importlib
import logging
import os
import time

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

from app.Core.decorators.batch_schedule import batch_schedule
from app.config import PROJECT_DIR_PATH

logger = logging.getLogger(__name__)

scheduler = AsyncIOScheduler()


def load_app_schedules():
    base_dir = PROJECT_DIR_PATH
    pattern = os.path.join(base_dir, "**", "schedules", "*.py")
    files = glob.glob(pattern, recursive=True)

    for path in files:
        if os.path.basename(path).startswith("_"):
            continue  # __init__.py ë“±ì€ ì œì™¸

        module_name = (
            path.replace(base_dir + os.sep, "").replace(os.sep, ".").replace(".py", "")
        )

        spec = importlib.util.spec_from_file_location(module_name, path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)


# @batch_schedule(CronTrigger(second=0))
# async def run_every_minute():
#     logger.warning("ğŸ” [ë§¤ë¶„ 0ì´ˆ] ë°°ì¹˜ ì‘ì—… ì‹œì‘")
#     # time.sleep(3)
#     # logger.info("ğŸ” [ë§¤ë¶„ 0ì´ˆ] ë°°ì¹˜ ì‘ì—… ì¢…ë£Œ")
#     # raise Exception("Batch Error Test")


@batch_schedule(CronTrigger(minute=30))
async def run_every_hour_at_half():
    logger.warning("ğŸ•§ [ë§¤ì‹œ 30ë¶„] ë°°ì¹˜ ì‘ì—…")


@batch_schedule(CronTrigger(hour=12))
async def run_every_day_noon():
    # ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ìƒë™ì‘ í™•ì¸ìš©
    logger.warning("ğŸ•§ [batch] ë§¤ì¼ 12:00 ë°°ì¹˜ ì‘ì—…")
```